{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T15:51:24.680574Z",
     "iopub.status.busy": "2025-12-06T15:51:24.679922Z",
     "iopub.status.idle": "2025-12-06T15:53:43.201116Z",
     "shell.execute_reply": "2025-12-06T15:53:43.200260Z",
     "shell.execute_reply.started": "2025-12-06T15:51:24.680548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/khyeh0719/amazon-berkley-product-dataset\n",
      "License(s): unknown\n",
      "Downloading amazon-berkley-product-dataset.zip to /kaggle/working/dataset\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5.62G/5.71G [00:07<00:00, 173MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.71G/5.71G [00:07<00:00, 816MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!echo '{\"username\":\"ayeshakhanu\",\"key\":\"KGAT_a828e9fc4df39a75e4db891c30d1fff4\"}' > ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d khyeh0719/amazon-berkley-product-dataset --unzip -p /kaggle/working/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T15:55:56.234885Z",
     "iopub.status.busy": "2025-12-06T15:55:56.234544Z",
     "iopub.status.idle": "2025-12-06T15:55:56.366468Z",
     "shell.execute_reply": "2025-12-06T15:55:56.365364Z",
     "shell.execute_reply.started": "2025-12-06T15:55:56.234855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found! Listing contents:\n",
      "images\tmeta.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = '/kaggle/working/dataset/'\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Dataset found! Listing contents:\")\n",
    "    !ls {dataset_path}\n",
    "else:\n",
    "    print(\"Dataset not found at /kaggle/working/dataset/. Check if download completed fully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T16:00:23.716251Z",
     "iopub.status.busy": "2025-12-06T16:00:23.715395Z",
     "iopub.status.idle": "2025-12-06T16:14:50.422636Z",
     "shell.execute_reply": "2025-12-06T16:14:50.421624Z",
     "shell.execute_reply.started": "2025-12-06T16:00:23.716215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Installing PyTorch3D \n",
    "!pip install \"git+https://github.com/facebookresearch/pytorch3d.git@stable\" --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T15:59:40.451595Z",
     "iopub.status.busy": "2025-12-06T15:59:40.451104Z",
     "iopub.status.idle": "2025-12-06T15:59:45.895011Z",
     "shell.execute_reply": "2025-12-06T15:59:45.893951Z",
     "shell.execute_reply.started": "2025-12-06T15:59:40.451555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trimesh\n",
      "  Downloading trimesh-4.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from trimesh) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->trimesh) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->trimesh) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->trimesh) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->trimesh) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->trimesh) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->trimesh) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->trimesh) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->trimesh) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->trimesh) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->trimesh) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->trimesh) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->trimesh) (2024.2.0)\n",
      "Downloading trimesh-4.10.0-py3-none-any.whl (736 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m736.6/736.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trimesh\n",
      "Successfully installed trimesh-4.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install trimesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T16:16:05.957486Z",
     "iopub.status.busy": "2025-12-06T16:16:05.956654Z",
     "iopub.status.idle": "2025-12-06T16:16:06.024191Z",
     "shell.execute_reply": "2025-12-06T16:16:06.023579Z",
     "shell.execute_reply.started": "2025-12-06T16:16:05.957448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "PyTorch3D version: 0.7.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch3d\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch3D version:\", pytorch3d.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:55:34.151934Z",
     "iopub.status.busy": "2025-12-06T22:55:34.151319Z",
     "iopub.status.idle": "2025-12-06T22:55:34.384330Z",
     "shell.execute_reply": "2025-12-06T22:55:34.383613Z",
     "shell.execute_reply.started": "2025-12-06T22:55:34.151908Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      image_path  instance_id  domain           product_type\n",
      "0  images/images/81NP7qh2L6L.jpg          292  amazon  MECHANICAL_COMPONENTS\n",
      "1  images/images/81A0u5L4VAL.jpg          292  amazon  MECHANICAL_COMPONENTS\n",
      "2  images/images/61xhS6iLrZL.jpg          292  amazon  MECHANICAL_COMPONENTS\n",
      "3  images/images/61Rp4qOih9L.jpg         6576  amazon                   SOFA\n",
      "4  images/images/81+4dBN1jsL.jpg        80675  amazon    CELLULAR_PHONE_CASE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta_path = '/kaggle/working/dataset/meta.csv'\n",
    "meta = pd.read_csv(meta_path)\n",
    "print(meta.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T20:27:15.274051Z",
     "iopub.status.busy": "2025-12-06T20:27:15.273383Z",
     "iopub.status.idle": "2025-12-06T20:27:15.279104Z",
     "shell.execute_reply": "2025-12-06T20:27:15.278412Z",
     "shell.execute_reply.started": "2025-12-06T20:27:15.274028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "\n",
    "image_dir = '/kaggle/working/dataset/images/'\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_image(image_name):\n",
    "    path = os.path.join(image_dir, image_name)\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  \n",
    "    return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T20:27:20.212734Z",
     "iopub.status.busy": "2025-12-06T20:27:20.212262Z",
     "iopub.status.idle": "2025-12-06T20:27:20.488026Z",
     "shell.execute_reply": "2025-12-06T20:27:20.487382Z",
     "shell.execute_reply.started": "2025-12-06T20:27:20.212709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([4, 3, 224, 224])\n",
      "Point clouds shape: torch.Size([4, 2048, 3])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import trimesh\n",
    "\n",
    "\n",
    "dataset_path = \"/kaggle/working/dataset\"\n",
    "images_root = dataset_path  \n",
    "pc_root = os.path.join(dataset_path, \"pointclouds\")  \n",
    "\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# \n",
    "class ImagePointCloudDataset(Dataset):\n",
    "    def __init__(self, meta_csv, img_root, pc_root, transform=None, num_points=2048):\n",
    "        self.meta = pd.read_csv(meta_csv)\n",
    "        self.img_root = img_root\n",
    "        self.pc_root = pc_root\n",
    "        self.transform = transform\n",
    "        self.num_points = num_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta.iloc[idx]\n",
    "\n",
    "        img_path = os.path.join(self.img_root, row['image_path'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "       \n",
    "        points = load_point_cloud(row['instance_id'], self.num_points)\n",
    "        if points is None:\n",
    "            \n",
    "            points = torch.zeros((self.num_points, 3), dtype=torch.float32)\n",
    "        \n",
    "        return image, points\n",
    "\n",
    "meta_csv_path = os.path.join(dataset_path, \"meta.csv\")\n",
    "dataset = ImagePointCloudDataset(meta_csv_path, images_root, pc_root, transform=preprocess, num_points=2048)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "images, points = next(iter(loader))\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Point clouds shape:\", points.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T20:27:26.382443Z",
     "iopub.status.busy": "2025-12-06T20:27:26.381847Z",
     "iopub.status.idle": "2025-12-06T20:27:28.228989Z",
     "shell.execute_reply": "2025-12-06T20:27:28.228260Z",
     "shell.execute_reply.started": "2025-12-06T20:27:26.382419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching point clouds...\n",
      "Caching complete! Total cached: 102203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_POINTS = 2048\n",
    "\n",
    "df = pd.read_csv(meta_csv_path)\n",
    "unique_ids = df[\"instance_id\"].unique()\n",
    "\n",
    "cached_pointclouds = {}\n",
    "\n",
    "print(\"Caching point clouds...\")\n",
    "\n",
    "for inst in unique_ids:\n",
    "    ply_path = os.path.join(pc_root, f\"{inst}.ply\")\n",
    "    if os.path.exists(ply_path):\n",
    "        mesh = trimesh.load(ply_path)\n",
    "        pts, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        cached_pointclouds[inst] = torch.tensor(pts, dtype=torch.float32)\n",
    "    else:\n",
    "        cached_pointclouds[inst] = torch.zeros((NUM_POINTS, 3), dtype=torch.float32)\n",
    "\n",
    "print(\"Caching complete! Total cached:\", len(cached_pointclouds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T17:39:50.169612Z",
     "iopub.status.busy": "2025-12-06T17:39:50.168830Z",
     "iopub.status.idle": "2025-12-06T17:39:50.174962Z",
     "shell.execute_reply": "2025-12-06T17:39:50.174308Z",
     "shell.execute_reply.started": "2025-12-06T17:39:50.169583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, df, img_root, transform):\n",
    "        self.df = df\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = os.path.join(self.img_root, row[\"image_path\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        inst_id = row[\"instance_id\"]\n",
    "        pc = cached_pointclouds[inst_id] \n",
    "\n",
    "        return image, pc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T17:40:17.570782Z",
     "iopub.status.busy": "2025-12-06T17:40:17.570276Z",
     "iopub.status.idle": "2025-12-06T17:40:17.574851Z",
     "shell.execute_reply": "2025-12-06T17:40:17.574108Z",
     "shell.execute_reply.started": "2025-12-06T17:40:17.570751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CachedDataset(df, images_root, preprocess)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T17:40:25.774011Z",
     "iopub.status.busy": "2025-12-06T17:40:25.773340Z",
     "iopub.status.idle": "2025-12-06T17:40:28.037874Z",
     "shell.execute_reply": "2025-12-06T17:40:28.037067Z",
     "shell.execute_reply.started": "2025-12-06T17:40:25.773985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "vgg = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "vgg.eval()\n",
    "feature_extractor = vgg.features\n",
    "\n",
    "class PointCloudMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, NUM_POINTS * 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, NUM_POINTS, 3)\n",
    "\n",
    "mlp = PointCloudMLP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T20:27:45.663520Z",
     "iopub.status.busy": "2025-12-06T20:27:45.662974Z",
     "iopub.status.idle": "2025-12-06T22:34:34.970249Z",
     "shell.execute_reply": "2025-12-06T22:34:34.969532Z",
     "shell.execute_reply.started": "2025-12-06T20:27:45.663492Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:21<00:00, 13.10it/s, loss=0.00118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Avg Loss: 0.001249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:21<00:00, 13.11it/s, loss=0.00108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Avg Loss: 0.001126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.14it/s, loss=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Avg Loss: 0.001037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.12it/s, loss=0.000948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Avg Loss: 0.000977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.15it/s, loss=0.00091] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Avg Loss: 0.000934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.13it/s, loss=0.000877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 Avg Loss: 0.000897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.15it/s, loss=0.00085] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 Avg Loss: 0.000870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.15it/s, loss=0.000834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 Avg Loss: 0.000842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.15it/s, loss=0.000812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 Avg Loss: 0.000824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.18it/s, loss=0.00017] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 Avg Loss: 0.000711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:20<00:00, 13.16it/s, loss=2.88e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 Avg Loss: 0.000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.19it/s, loss=0.000563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 Avg Loss: 0.000225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.18it/s, loss=2.71e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 Avg Loss: 0.000133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.18it/s, loss=6.14e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 Avg Loss: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.19it/s, loss=2.6e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 Avg Loss: 0.000334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:18<00:00, 13.20it/s, loss=4.33e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 Avg Loss: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.19it/s, loss=9.12e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 Avg Loss: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:18<00:00, 13.20it/s, loss=3.09e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 Avg Loss: 0.000372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:18<00:00, 13.19it/s, loss=4.45e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 Avg Loss: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [06:19<00:00, 13.18it/s, loss=0.000146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 Avg Loss: 0.000035\n",
      "TRAINING COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler, autocast\n",
    "import random\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 4  \n",
    "subset_size = 5000\n",
    "save_path = \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "total_indices = list(range(len(dataset)))  \n",
    "subset_indices = random.sample(total_indices, subset_size)\n",
    "subset_dataset = Subset(dataset, subset_indices)\n",
    "loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "scaler = GradScaler(device=\"cuda\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    mlp.train()\n",
    "    feature_extractor.eval()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for images, gt_pc in pbar:\n",
    "        images = images.to(device)\n",
    "        gt_pc = gt_pc.to(device)\n",
    "\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            feats = feature_extractor(images)\n",
    "            feats = feats.view(feats.size(0), -1)\n",
    "\n",
    "        \n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            pred_pc = mlp(feats)\n",
    "            loss = chamfer_distance(pred_pc, gt_pc)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "\n",
    "    checkpoint_file = os.path.join(save_path, f\"mlp_epoch{epoch+1}.pth\")\n",
    "    torch.save(mlp.state_dict(), checkpoint_file)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} Avg Loss: {running_loss/len(loader):.6f}\", flush=True)\n",
    "\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:41:35.028717Z",
     "iopub.status.busy": "2025-12-06T22:41:35.028109Z",
     "iopub.status.idle": "2025-12-06T22:41:35.903028Z",
     "shell.execute_reply": "2025-12-06T22:41:35.902177Z",
     "shell.execute_reply.started": "2025-12-06T22:41:35.028688Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(mlp.state_dict(), \"mlp_epoch20.pth\")\n",
    "print(\"Model Saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:43:08.935038Z",
     "iopub.status.busy": "2025-12-06T22:43:08.934452Z",
     "iopub.status.idle": "2025-12-06T22:43:12.002695Z",
     "shell.execute_reply": "2025-12-06T22:43:12.001928Z",
     "shell.execute_reply.started": "2025-12-06T22:43:08.935002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ MODEL LOADED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "NUM_POINTS = 5000   \n",
    "\n",
    "class PointCloudMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, NUM_POINTS * 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, NUM_POINTS, 3)\n",
    "\n",
    "vgg = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "vgg.eval()\n",
    "feature_extractor = vgg.features\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mlp = PointCloudMLP().to(device)\n",
    "\n",
    "\n",
    "MODEL_PATH = \"mlp_epoch20.pth\"\n",
    "\n",
    "mlp.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "mlp.eval()\n",
    "\n",
    "print(\"üöÄ MODEL LOADED SUCCESSFULLY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:47:04.068834Z",
     "iopub.status.busy": "2025-12-06T22:47:04.067709Z",
     "iopub.status.idle": "2025-12-06T22:47:04.338097Z",
     "shell.execute_reply": "2025-12-06T22:47:04.337503Z",
     "shell.execute_reply.started": "2025-12-06T22:47:04.068770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/images/81NP7qh2L6L.jpg</td>\n",
       "      <td>292</td>\n",
       "      <td>amazon</td>\n",
       "      <td>MECHANICAL_COMPONENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/images/81A0u5L4VAL.jpg</td>\n",
       "      <td>292</td>\n",
       "      <td>amazon</td>\n",
       "      <td>MECHANICAL_COMPONENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/images/61xhS6iLrZL.jpg</td>\n",
       "      <td>292</td>\n",
       "      <td>amazon</td>\n",
       "      <td>MECHANICAL_COMPONENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/images/61Rp4qOih9L.jpg</td>\n",
       "      <td>6576</td>\n",
       "      <td>amazon</td>\n",
       "      <td>SOFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/images/81+4dBN1jsL.jpg</td>\n",
       "      <td>80675</td>\n",
       "      <td>amazon</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image_path  instance_id  domain           product_type\n",
       "0  images/images/81NP7qh2L6L.jpg          292  amazon  MECHANICAL_COMPONENTS\n",
       "1  images/images/81A0u5L4VAL.jpg          292  amazon  MECHANICAL_COMPONENTS\n",
       "2  images/images/61xhS6iLrZL.jpg          292  amazon  MECHANICAL_COMPONENTS\n",
       "3  images/images/61Rp4qOih9L.jpg         6576  amazon                   SOFA\n",
       "4  images/images/81+4dBN1jsL.jpg        80675  amazon    CELLULAR_PHONE_CASE"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_csv(\"/kaggle/working/dataset/meta.csv\")\n",
    "meta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:47:14.282240Z",
     "iopub.status.busy": "2025-12-06T22:47:14.281451Z",
     "iopub.status.idle": "2025-12-06T22:47:14.290173Z",
     "shell.execute_reply": "2025-12-06T22:47:14.289582Z",
     "shell.execute_reply.started": "2025-12-06T22:47:14.282213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images Found: 264904\n",
      "0  ‚Üí  images/images/81NP7qh2L6L.jpg\n",
      "1  ‚Üí  images/images/81A0u5L4VAL.jpg\n",
      "2  ‚Üí  images/images/61xhS6iLrZL.jpg\n",
      "3  ‚Üí  images/images/61Rp4qOih9L.jpg\n",
      "4  ‚Üí  images/images/81+4dBN1jsL.jpg\n",
      "5  ‚Üí  images/images/81RoDPeqygL.jpg\n",
      "6  ‚Üí  images/images/61LWeNhjZ9L.jpg\n",
      "7  ‚Üí  images/images/618uWaH5elL.jpg\n",
      "8  ‚Üí  images/images/61hUyEcVYtL.jpg\n",
      "9  ‚Üí  images/images/61ajxcF6Y1L.jpg\n",
      "10  ‚Üí  images/images/614jfuPGINL.jpg\n",
      "11  ‚Üí  images/images/61izEZdhlaL.jpg\n",
      "12  ‚Üí  images/images/717gxIR99XL.jpg\n",
      "13  ‚Üí  images/images/51fzW5BNdVL.jpg\n",
      "14  ‚Üí  images/images/21xD1NzxObL.jpg\n",
      "15  ‚Üí  images/images/71QdPoaGvYL.jpg\n",
      "16  ‚Üí  images/images/71z2XJ0DW2L.jpg\n",
      "17  ‚Üí  images/images/81RNHjN1X5L.jpg\n",
      "18  ‚Üí  images/images/81Ay4WEWSdL.jpg\n",
      "19  ‚Üí  images/images/61Q0baX067L.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths = meta[\"image_path\"].tolist()\n",
    "\n",
    "print(\"Total Images Found:\", len(image_paths))\n",
    "for i, p in enumerate(image_paths[:20]):\n",
    "    print(i, \" ‚Üí \", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:58:30.033176Z",
     "iopub.status.busy": "2025-12-06T23:58:30.032289Z",
     "iopub.status.idle": "2025-12-06T23:58:30.037149Z",
     "shell.execute_reply": "2025-12-06T23:58:30.036424Z",
     "shell.execute_reply.started": "2025-12-06T23:58:30.033140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import trimesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:58:35.615002Z",
     "iopub.status.busy": "2025-12-06T23:58:35.614310Z",
     "iopub.status.idle": "2025-12-06T23:58:37.090711Z",
     "shell.execute_reply": "2025-12-06T23:58:37.090163Z",
     "shell.execute_reply.started": "2025-12-06T23:58:35.614968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading VGG16\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16.eval()\n",
    "vgg16_features = vgg16.features  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:58:42.940533Z",
     "iopub.status.busy": "2025-12-06T23:58:42.940275Z",
     "iopub.status.idle": "2025-12-06T23:58:51.720038Z",
     "shell.execute_reply": "2025-12-06T23:58:51.719435Z",
     "shell.execute_reply.started": "2025-12-06T23:58:42.940515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc): Linear(in_features=25088, out_features=45000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_POINTS = 15000  \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, NUM_POINTS, 3)  \n",
    "\n",
    "mlp = MLP(input_size=25088, output_size=NUM_POINTS*3)\n",
    "mlp.eval()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:59:19.929738Z",
     "iopub.status.busy": "2025-12-06T23:59:19.928896Z",
     "iopub.status.idle": "2025-12-06T23:59:19.940215Z",
     "shell.execute_reply": "2025-12-06T23:59:19.939585Z",
     "shell.execute_reply.started": "2025-12-06T23:59:19.929705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_path = \"dataset/images/images/61izEZdhlaL.jpg\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "img_tensor = preprocess(img).unsqueeze(0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:59:41.034782Z",
     "iopub.status.busy": "2025-12-06T23:59:41.034283Z",
     "iopub.status.idle": "2025-12-06T23:59:41.601406Z",
     "shell.execute_reply": "2025-12-06T23:59:41.600607Z",
     "shell.execute_reply.started": "2025-12-06T23:59:41.034759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = vgg16_features(img_tensor)\n",
    "    features = features.view(features.size(0), -1)  \n",
    "    pred_pc = mlp(features)\n",
    "    pred_pc = pred_pc.squeeze(0).cpu().numpy()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T00:22:50.088926Z",
     "iopub.status.busy": "2025-12-07T00:22:50.088647Z",
     "iopub.status.idle": "2025-12-07T00:22:50.392525Z",
     "shell.execute_reply": "2025-12-07T00:22:50.391931Z",
     "shell.execute_reply.started": "2025-12-07T00:22:50.088907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=4096, out_features=6144, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/kaggle/working/checkpoints/mlp_epoch20.pth\"\n",
    "mlp.load_state_dict(torch.load(checkpoint_path))\n",
    "mlp.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T00:59:24.638363Z",
     "iopub.status.busy": "2025-12-07T00:59:24.637613Z",
     "iopub.status.idle": "2025-12-07T00:59:26.152418Z",
     "shell.execute_reply": "2025-12-07T00:59:26.151627Z",
     "shell.execute_reply.started": "2025-12-07T00:59:24.638335Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved permanently as mlp_final.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(mlp.state_dict(), \"mlp_final.pth\")\n",
    "print(\" Model saved permanently as mlp_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T11:11:30.710472Z",
     "iopub.status.busy": "2025-12-07T11:11:30.709857Z",
     "iopub.status.idle": "2025-12-07T11:11:30.715601Z",
     "shell.execute_reply": "2025-12-07T11:11:30.715025Z",
     "shell.execute_reply.started": "2025-12-07T11:11:30.710451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876667.glb saved to '/kaggle/working'\n",
      "744877.glb saved to '/kaggle/working'\n",
      "778550.glb saved to '/kaggle/working'\n",
      "384975.glb saved to '/kaggle/working'\n",
      "732244.glb saved to '/kaggle/working'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import radom\n",
    "\n",
    "working_dir = \"/kaggle/working\"\n",
    "images_dir = os.path.join(working_dir, \"dataset/images/images\")\n",
    "mesh_dir = os.path.join(working_dir)\n",
    "os.makedirs(mesh_dir, exist_ok=True)\n",
    "\n",
    "random_images = random.sample([f for f in os.listdir(images_dir) if f.endswith(\".jpg\")], 5)\n",
    "\n",
    "vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "vgg.eval()\n",
    "feature_extractor = vgg.features\n",
    "\n",
    "NUM_POINTS = 5000\n",
    "class PointCloudMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, NUM_POINTS*3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, NUM_POINTS, 3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlp = PointCloudMLP().to(device)\n",
    "\n",
    "MODEL_PATH = os.path.join(working_dir, \"mlp_epoch20.pth\")\n",
    "mlp.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "mlp.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if not img_file.endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(images_dir, img_file)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = feature_extractor(img_tensor)\n",
    "        feats = feats.view(feats.size(0), -1)  \n",
    "\n",
    "        pred_pc = mlp(feats)  \n",
    "        pred_pc = pred_pc.squeeze(0).cpu().numpy()  \n",
    "\n",
    "    \n",
    "    ply_name = f\"{img_file.split('.')[0]}.ply\"\n",
    "    ply_path = os.path.join(mesh_dir, ply_name)\n",
    "    \n",
    "\n",
    "    print(f\"{ply_name} saved to {working_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
